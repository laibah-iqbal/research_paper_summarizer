{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f38e4f6-bff8-4106-ba32-bbdc4ef4a4d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Motivation ##\n",
    "\n",
    "As a Master's student, sometimes I don't always have the time to complete all my readings especially lengthy research papers that supplement the course material. So, to be able to keep up with them when I'm in a crunch, I used Python libraries to parse research paper PDFs, summarize them and output the summary as an audio file so I can listen to research papers with all my other chores.\n",
    "\n",
    "Below is the code I used to accomplish this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9495942-c02d-4ee9-a501-2979a661d6cf",
   "metadata": {},
   "source": [
    "#### Importing required packages ###\n",
    "\n",
    "I used fitz from the pymuPDF package to read in the PDF in xml format. I parsed the XML using the ElementTree package. Summarizing of the text was done use the Natural Language Toolkit and I output the audio as an mp3 file using Google's text to speech API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d4227c62-7aa7-4a41-9060-5dc55e94679d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import fitz\n",
    "import xml.etree.ElementTree as ET\n",
    "from gtts import gTTS \n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "22509e6d-37e1-4b82-b384-34c697f762b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the PDF\n",
    "file_name = \"research_paper.pdf\"\n",
    "doc = fitz.open(file_name, filetype=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735b4316-410d-47d9-aa74-4bee91efedff",
   "metadata": {},
   "source": [
    "## PDF Parsing ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3250f2-b849-497c-a727-3cd3f4923440",
   "metadata": {},
   "source": [
    "#### Helper functions ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "650d40b2-77ce-4514-89da-7d301239b662",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def xml_parser(xml):\n",
    "    \n",
    "    ''' This function takes a pdf page read as xml and extracts text from it.\n",
    "    It stores the text in the form of nested dictionaries where each key:value pair \n",
    "    in the outer dictionary is font name:dictionary of font sizes. \n",
    "    The inner dictionary contains key:value pairs of font_size:text '''\n",
    "    \n",
    "    font_blocks = {}\n",
    "    for block in xml.findall('block'):\n",
    "        for line in block.findall('line'):\n",
    "            for font in line.findall('font'):\n",
    "                \n",
    "                if font_blocks.get(font.get('name'),\"NA\") == \"NA\":\n",
    "                    font_blocks[font.get('name')] = {}\n",
    "                \n",
    "                if font_blocks[font.get('name')].get(font.get('size'),\"NA\") == \"NA\":\n",
    "                    font_blocks[font.get('name')][font.get('size')] = ''\n",
    "                \n",
    "                font_blocks[font.get('name')][font.get('size')] = \\\n",
    "                font_blocks[font.get('name')][font.get('size')] + \" \"\n",
    "                for char in font.findall('char'):\n",
    "                    try:\n",
    "                        font_blocks[font.get('name')][font.get('size')] = font_blocks[font.get('name')][font.get('size')] + char.get('c')\n",
    "                    except Exception as e: \n",
    "                        pass\n",
    "    return font_blocks\n",
    "\n",
    "def get_paper_text(paper_dictionary):\n",
    "    ''' This function takes a list of nested dictionaries from xml_parser,\n",
    "    and compiles them into one dictionary so that all pages of the PDF are compiled\n",
    "    into one nested dictionary. '''\n",
    "    \n",
    "    fonts = {}\n",
    "    for page in paper_dictionary:\n",
    "        for font in page:\n",
    "            #print(page[font])\n",
    "            if fonts.get(font,\"NA\") == \"NA\":\n",
    "                fonts[font] = {}\n",
    "            for size in page[font]:\n",
    "                if fonts[font].get(size,\"NA\") == \"NA\":\n",
    "                    fonts[font][size] = ''\n",
    "                try:\n",
    "                    fonts[font][size] = fonts[font][size] + page[font][size]\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "    return fonts\n",
    "\n",
    "def get_main_body(dict_):\n",
    "    \n",
    "    ''' This function takes the output from get_paper_text and finds the longest\n",
    "    text in it. This is the actual content of the research paper with footnotes, \n",
    "    references, page numbers, titles, etc. removed '''\n",
    "    \n",
    "    max_ = 0\n",
    "    for font in dict_:\n",
    "        for size in dict_[font]:\n",
    "            if len(dict_[font][size]) > max_:\n",
    "                max_ = len(dict_[font][size])\n",
    "    \n",
    "    for font in dict_:\n",
    "        for size in dict_[font]:\n",
    "            if len(dict_[font][size]) == max_:\n",
    "                return dict_[font][size]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "c705ae02-20be-40ed-af7f-44b71bba249e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Call xml_parser on each page and store the content of each page in the form \n",
    "# of nested dictionaries in a list\n",
    "entire_doc = []\n",
    "for page in doc:\n",
    "    xml = page.get_text(\"xml\")\n",
    "    text_ = ET.fromstring(xml)\n",
    "    entire_doc.append(xml_parser(text_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "2b1445d4-d7a9-4595-b191-82d62b3b35a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# paper2 now holds the main body (content) of the research paper.\n",
    "paper2 = get_main_body(get_paper_text(entire_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94400127-cfe0-4fd8-a92f-13efacbb57a5",
   "metadata": {},
   "source": [
    "## Text Summarizing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "67bbf9ca-28fe-4481-85b7-624d7e3632d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stopWords = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "4ccd13d3-9b3f-4b63-925f-04fc3869d9f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' Tokenize words, remove stopwords, and store them \n",
    "in a dictionary along with their frequency '''\n",
    "words = word_tokenize(paper2)\n",
    "freqTable = dict()\n",
    "for word in words:\n",
    "    word = word.lower()\n",
    "    if word in stopWords:\n",
    "        continue\n",
    "    if word in freqTable:\n",
    "        freqTable[word] += 1\n",
    "    else:\n",
    "        freqTable[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "a6c2e02e-ea4e-4a3f-894e-9e0a98e92456",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' Tokenize the sentences then stores them in a dictionary against their value.\n",
    "Value is greater if the sentence includes more important words (more frequent words). '''\n",
    "\n",
    "sentences = sent_tokenize(paper2)\n",
    "sentenceValue = dict()\n",
    "\n",
    "for sentence in sentences:\n",
    "    for word, freq in freqTable.items():\n",
    "        if word in sentence.lower():\n",
    "            if word in sentence.lower():\n",
    "                if sentence in sentenceValue:\n",
    "                    sentenceValue[sentence] += freq\n",
    "                else:\n",
    "                    sentenceValue[sentence] = freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "45812bb9-3e53-43c9-99da-10fd15be0e93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' The average sentence value is calculated '''\n",
    "sumValues = 0\n",
    "for sentence in sentenceValue:\n",
    "    sumValues += sentenceValue[sentence]\n",
    "\n",
    "average = int(sumValues / len(sentenceValue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "08925892-6cd2-492d-8a2c-60092526a248",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' Each sentence's value is compared to the average sentence value.\n",
    "If it's value is greater than > 1.2*average, it is considered important enough \n",
    "to be in the summary '''\n",
    "summary = ''\n",
    "\n",
    "for sentence in sentences:\n",
    "    if (sentence in sentenceValue) and (sentenceValue[sentence] > (1.2 * average)):\n",
    "        summary += \" \" + sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "efd6338b-d85c-4e58-a8fd-032cc4e539bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the paper has been reduced by 43.37%\n"
     ]
    }
   ],
   "source": [
    "def floored_percentage(val, digits):\n",
    "    val *= 10 ** (digits + 2)\n",
    "    return '{1:.{0}f}%'.format(digits, floor(val) / 10 ** digits)\n",
    "\n",
    "print(\"Length of the paper has been reduced by \" \\\n",
    "      + floored_percentage(((len(paper2)-len(summary))/len(paper2)),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "ed8d0e4c-b948-4db6-97f3-fa499bd3b001",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There is—or was, mostly, in the 1980s—the whole mass of research and trade literature on the much  misrepresented Turing test that would ostensibly show whether my unknown interlocutor is human or a machine,  and it was all about intelligence. Since then, our notion of intelligence has changed radically with regard to artificial  intelligence while our understanding of our own minds, unadvanced significantly either by the revolutionary  progress with mapping the human genome or by mapping out the human brain, has not progressed that much. In fact, if asked to think of a human mental functionality that a robot or any computer is not capable of, an  educated mature thinker will mention language, culture, humor, and on all of those counts, the situation is not clear. The computer can barely do anything with understanding, even though it can output tons of text, for  instance, answer my command to print out any text, including creating new ones, e.g., the list of all human diseases. This paper will explore robotic intelligence as a particular kind of AI (Section 2), argue for the use of natural  language, with understanding capabilities by non-humans in CHARMS (Section 3), and briefly mention Ontological  Semantic Technology as a mature implementation of this approach (Section 4). A semantically innocent roboticist,  especially one brainwashed by machine-learning-only education should understand that this paper is based on two  non-machine-learning principles: it is rule-based rather than statistical and it is meaning-based rather than bag-of- words-based. Nor should it be read as an attempt to project human collaboration into CHARMS—rather, it is a claim  that both should be based on a solid computational semantic foundation. But, first, let us  make it clear how   human intelligence,   AI,   computer intelligence,   web intelligence,   agent intelligence, and our subject,   robotic intelligence,   relate to each other:  Human intelligence includes all mental activities underlying human lives. Artificial intelligence (AI) emulates parts and aspects of human intelligence in computer applications, where the  machine attempts to fulfill a human intellectual task. The somewhat simplistic view in early AI, with its largely  exaggerated expectations and false hopes, was that if such an application is reasonably successful, we would then  understand how human intelligence does it because we would, of course, have designed the computer algorithm  ourselves. As the field was growing older—I don’t want to say, maturing—it became clear that the computer may  employ other than human-like methods to achieve some plausible-looking results. These efforts are also not satisfactory in NLP applications because even their souped-up precision rate of 80%  (really, around 60%) is significantly lower than the human user’s 95+% expectation of accuracy     (make it a  maximum 5% error tolerance). Both intelligent agents and robots are full-fledged participants of the HARMS hybrid  teams, and the whole thrust of the CHARMS system is to maximize the autonomy and, hence, intelligence of the  computational components. The fascinating difference that robotic intelligence adds is the cyberphysicality of the  robots: they do exist in the physical space, which means having dimensions, being subject to time restrictions and  abilities to move, etc. While the machines and sensors must be mechanically, optically, etc., improved to the best of the state  of the arts, the humans, agents, and robots should contribute their intelligence, and for us, in robotic intelligence and  communication, it means forever maximizing and optimizing the autonomy, intelligence, and productivity of the  robots. As we have shown in previous publications, there are several parameters defining the space where CHARMS is;  Organization:  human and other control,  division of labor,  specialization, optimization, and duplication avoidance,  Communication:  reporting and understanding,  interlanguage translation. One would think that all of these areas would have been studied extensively and intensively in such diverse fields  as control theory, ergonomics, corporate and industrial communication, and NLP, and they have, but never really the  way CHARMS can use. Contrary to hybrid human-robot-agent-collaboration, inter-human collaboration has been  studied intensely from several disciplinary and interdisciplinary perspectives: those of sociology, management,  industrial engineering/ergonomics, human factors, rhetoric/usability, but it is not easily adjustable to the machine- language algorithmic environment because, inevitably, whether explicitly or implicitly, those studies depend on  human perception and intelligence. More pertinent to this research, some of aspects of inter-human collaboration  were subsequently extended to intelligent agents, and dominant among those are the belief-desire-intention (BDI)  studies of intelligent agents ; rooted in influential scholarship  on plans and intentions—see also Wooldridge . But even those—or certainly efforts of the COIN clique--do not reach the  level of formality (meaning no human intelligence involved), sophistication and upward scalability that CHARMS  must allow for. Even more to the point, significant work has been done on the construction of practical, domain- independent teamwork models and architectures , and some of that scholarship is already absorbed in  CHARMS (it is interesting to note, however, that Tambe, the leader of that effort, is no longer continuing with it). Somewhat less pertinently perhaps but not without some relevance to us, there have been some reverberations of  the 1980s much misguided philosophical discourse about ways to separate human intelligence from machine  intelligence (without knowing much about either at the time), in which the Turing Test was loosely metaphorized,  if not actually parodied  . Going back to Section 1, CHARMS is designed to make the task of  differentiating between manifestations of human and artificial intelligence even harder than presented there. While there  has apparently been no prior work on porting the Natural Language Processing (NLP) technology, let alone  Computational Semantic or any meaning processing technology, into supporting the robot/agent communication  without limiting it to specific commands or menus, there have, however, been somewhat pertinent efforts in NLP  involving intelligent agents, for instance . Their focus has been on emulating dialog participation by the computer  with a single human, and valuable insights have been achieved but not concerning real-life robotic agents nor  dealing directly with their native systems of communication—and not with fully semantic methods. Part of the reason for that paucity of robot-human communication research would be that active collaboration  between agent and NLP research groups, outside of CHARMS, has yet to take off, and, hopefully, this effort may  lead to more such interdisciplinary efforts. Another reason may be that the problem of the communication system  among humans, robots, and agents lacks the main premises and constituents, such as large corpora of related texts,  for the successful applications of currently dominant non-representative, non-rule-based, non-semantic methods. The syntax-, statistics-, and machine-learning-based approaches have dominated NLP for several decades and have  made very significant inroads into classifying and clustering texts without understanding them and without spending  efforts on acquiring such resources as machine-tractable repositories of meanings. To facilitate robot-human communication, a radically different approach has been attempted, the one similar to  the natural development of Pidgin English in the 19th century to mitigate English-Chinese communication in the  ports of sea trade, or to the invention of Esperanto, a naive attempt to develop the ”easiest” natural language that  combines the features of the ”most efficient languages” so that it could be adopted as the international language. ROILA , a spoken language for talking to robots makes both of these claims: it is billed as simple, easy, and  exception-free—and it is foreign to both sides, human and robotic, and has to be learned from scratch. Probably the closest NLP has ever come to handling problems that are similar to the ones we deal with in this  proposal is in the never-dying dream to program in natural language, a dream that recurs with almost every new  approach to NLP—for the latest efforts in this direction, see, for instance . Throughout this time, our computational semantics, or meaning- and rule-based NLP, has been addressing  applications where the very nature of the task calls for comprehensive and direct meaning access, and we proceed on  the premise that the hybrid communication does not have to—nor will or should it—generate multimillion-word  corpora that lend themselves to the statistical methods. It was when Julia Taylor and I, triggered by our participation in Eric Matson’s First Summer  School on  Humanoid Robotics at Purdue in 2011, realized that our ontology was non-language-specific much more strongly: it  underlay formal languages and robotic systems just as it did all natural languages, databases, images and other forms  of information. In simple terms, ontology-equipped robot “understands” the meaning of   in exactly the same  way as its human partner understand the English word—or, for that matter, its counterpart in any other language:  namely, they relate it to its ontological concept. The OST ontology equips the CHARMS robots with a sense, heavily bolstered and  additionally anchored with its physicality of its:  place in the world,  partners,  physical parameters,  position,  movements,  repertoire of functions,  and many other elements of knowledge that robot designers and users may not be aware of.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c76e8e7-30e6-4d48-9552-1b8cf4ad3b56",
   "metadata": {},
   "source": [
    "## Text to Speech ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "df2f7c02-6b4c-4bfe-b3fe-13bdee3854cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "language = 'en'\n",
    "myobj = gTTS(text=summary, lang=language, slow=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "dd3d6745-3832-4f47-bf8e-c5eb22cabf50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "myobj.save(\"paper.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d66629fc-ab1e-4dc6-9fd4-ae455ccaf179",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"paper.mp3\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
